1. Fixed acidity, volatile acidity, citric acid, chlorides, free sulfur dioxide, and total sulfur dioxide all seem to have outliers, a few points that are significantly removed from the rest of the data. 
2. The accuracy achieved by ZeroR is 62.381%, which is the percentage of wines classified as 'bad' in the training set. This makes sense, as ZeroR simply chooses the majority class in all cases. This can be a helpful baseline as it can show whether other classifiers are better or worse than just guessing. If another classifier is significantly better than ZeroR, then we can assume that it has accurately found some correlation between the attributes and classification. 
3. The most informative single feature for this task is alcohol content. The higher the alcohol content, the more likely the wine quality is to be good. 
4. 95.873% -> 85.979%. 10-fold cross-validation involves splitting the training set into 10 equally sized subsets and using 1 as test data and the other 9 as training data. The main reason the percentage differs is that when measuring accuracy with the training set, the decision tree is specifically tailored to perform well with the training set. This can give an artificially high accuracy. By splitting the data into a training set and a test set, we are more closely approximating the performance of the decision tree on a set that it was not specifically tailored for. This makes 10-fold cross-validation very important, as it can give us a much better idea of how our decision tree performs in general. 
5. "J48graft -C 0.25 -M 1 -A -E", 86.455%
6. I chose the model based entirely on what seemed to give the highest percentage accuracy. I first went through the different decision tree algorithms, and then attempted varying model parameters. The one I came up with had the highest accuracy that I was able to get. 
7. I diagree with this statement. While machine learning algorithms are extremely powerful and very useful, they have one major flaw: they can only approximate an underlying function. While it is hypothetically possible for an ML algorithm to approximate a function exactly, it is still useful to derive the underlying function itself. This is because it is ultimately more powerful to be able to use a function underlying a model if we simply have the function itself defined. ML is useful when we don't know that function, but it is still an intermediary step; knowing the function itself is more useful and allows us to skip that intermediary step of figuring it out. 
 8. My strategy was to go through the various kinds of trees and model parameters and see if one gave a particularly high or low accuracy on the car data. I then checked the wine data with the same classifier to see whether it performed differently or not. 
 9. It would seem that the key difference is that the car data has four different possible outputs, while the wine data has only two possible outputs. 